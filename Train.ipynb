{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1gezGK_665nrdj7yHa8pEU0sdM_myxrC-","authorship_tag":"ABX9TyPku3qFcJqmYPmyU5bWHo4j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_MU4wNclZQor","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582625872,"user_tz":-360,"elapsed":2435,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["from __future__ import print_function\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n","from keras.layers import Conv2D,MaxPooling2D\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"lOWiwMiwZh5n","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582630054,"user_tz":-360,"elapsed":2291,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["num_classes = 5\n","img_rows,img_cols = 48,48\n","batch_size = 32\n","\n","train_data_dir = '/content/drive/My Drive/Colab Notebooks/train'\n","validation_data_dir = '/content/drive/My Drive/Colab Notebooks/validation'\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjU7QC7ZZ3Xg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582636201,"user_tz":-360,"elapsed":2796,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["train_datagen = ImageDataGenerator(\n","\t\t\t\t\trescale=1./255,\n","\t\t\t\t\trotation_range=30,\n","\t\t\t\t\tshear_range=0.3,\n","\t\t\t\t\tzoom_range=0.3,\n","\t\t\t\t\twidth_shift_range=0.4,\n","\t\t\t\t\theight_shift_range=0.4,\n","\t\t\t\t\thorizontal_flip=True,\n","\t\t\t\t\tfill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"MOCpZS8oaCSF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600582653563,"user_tz":-360,"elapsed":14604,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}},"outputId":"2e2c0f00-3db7-41c0-a03e-86f88884b935"},"source":["train_generator = train_datagen.flow_from_directory(\n","\t\t\t\t\ttrain_data_dir,\n","\t\t\t\t\tcolor_mode='grayscale',\n","\t\t\t\t\ttarget_size=(img_rows,img_cols),\n","\t\t\t\t\tbatch_size=batch_size,\n","\t\t\t\t\tclass_mode='categorical',\n","\t\t\t\t\tshuffle=True)\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","\t\t\t\t\t\t\tvalidation_data_dir,\n","\t\t\t\t\t\t\tcolor_mode='grayscale',\n","\t\t\t\t\t\t\ttarget_size=(img_rows,img_cols),\n","\t\t\t\t\t\t\tbatch_size=batch_size,\n","\t\t\t\t\t\t\tclass_mode='categorical',\n","\t\t\t\t\t\t\tshuffle=True)\n","\n","model = Sequential()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found 24288 images belonging to 5 classes.\n","Found 5937 images belonging to 5 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KbuZ0AkfaSEM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582660605,"user_tz":-360,"elapsed":2967,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-1\n","\n","model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0lexrRGam5v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582667773,"user_tz":-360,"elapsed":4344,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-2 \n","\n","model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_St4JVyXa2yl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582675138,"user_tz":-360,"elapsed":4570,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-3\n","\n","model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3CeR3ERbA5E","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582680168,"user_tz":-360,"elapsed":1799,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-4 \n","\n","model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.2))\n","\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeYJgriYh0K4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582686263,"user_tz":-360,"elapsed":3382,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-5\n","\n","model.add(Flatten())\n","model.add(Dense(64,kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRueQ4OTh446","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582691489,"user_tz":-360,"elapsed":2827,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-6\n","\n","model.add(Dense(64,kernel_initializer='he_normal'))\n","model.add(Activation('elu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FJiGRnMh-UH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600582694620,"user_tz":-360,"elapsed":1162,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}}},"source":["# Block-7\n","\n","model.add(Dense(num_classes,kernel_initializer='he_normal'))\n","model.add(Activation('softmax'))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"rbrAoUuEiJgO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600596507986,"user_tz":-360,"elapsed":4576342,"user":{"displayName":"shovon Shuvo","photoUrl":"","userId":"05895838234971953814"}},"outputId":"40832b09-6f26-4b2c-814a-b328a73ba0a0"},"source":["print(model.summary())\n","\n","from keras.optimizers import RMSprop,SGD,Adam\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","\n","checkpoint = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5',\n","                             monitor='val_loss',\n","                             mode='min',\n","                             save_best_only=True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor='val_loss',\n","                          min_delta=0,\n","                          patience=3,\n","                          verbose=1,\n","                          restore_best_weights=True\n","                          )\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n","                              factor=0.2,\n","                              patience=3,\n","                              verbose=1,\n","                              min_delta=0.0001)\n","\n","callbacks = [earlystop,checkpoint,reduce_lr]\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer = Adam(lr=0.001),\n","              metrics=['accuracy'])\n","\n","nb_train_samples = 24176\n","nb_validation_samples = 3006\n","epochs=25\n","\n","history=model.fit_generator(\n","                train_generator,\n","                steps_per_epoch=nb_train_samples//batch_size,\n","                epochs=epochs,\n","                callbacks=callbacks,\n","                validation_data=validation_generator,\n","                validation_steps=nb_validation_samples//batch_size)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 48, 48, 32)        320       \n","_________________________________________________________________\n","activation (Activation)      (None, 48, 48, 32)        0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 48, 48, 32)        128       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 48, 48, 32)        9248      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 48, 48, 32)        0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 24, 24, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 12, 12, 128)       512       \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 6, 6, 256)         295168    \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 6, 6, 256)         1024      \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 6, 6, 256)         590080    \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 6, 6, 256)         0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 6, 6, 256)         1024      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2304)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                147520    \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 64)                256       \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 5)                 325       \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 5)                 0         \n","=================================================================\n","Total params: 1,328,037\n","Trainable params: 1,325,861\n","Non-trainable params: 2,176\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:From <ipython-input-12-0326e4609f9c>:41: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/25\n","755/755 [==============================] - ETA: 0s - loss: 1.8639 - accuracy: 0.2377 \n","Epoch 00001: val_loss improved from inf to 1.53185, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 11431s 15s/step - loss: 1.8639 - accuracy: 0.2377 - val_loss: 1.5318 - val_accuracy: 0.3152\n","Epoch 2/25\n","754/755 [============================>.] - ETA: 0s - loss: 1.5778 - accuracy: 0.2800\n","Epoch 00002: val_loss improved from 1.53185 to 1.51815, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 929s 1s/step - loss: 1.5776 - accuracy: 0.2801 - val_loss: 1.5182 - val_accuracy: 0.3172\n","Epoch 3/25\n","755/755 [==============================] - ETA: 0s - loss: 1.5513 - accuracy: 0.2973\n","Epoch 00003: val_loss did not improve from 1.51815\n","755/755 [==============================] - 458s 606ms/step - loss: 1.5513 - accuracy: 0.2973 - val_loss: 1.5507 - val_accuracy: 0.2947\n","Epoch 4/25\n","754/755 [============================>.] - ETA: 0s - loss: 1.5409 - accuracy: 0.3047\n","Epoch 00004: val_loss improved from 1.51815 to 1.44276, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 265s 352ms/step - loss: 1.5409 - accuracy: 0.3047 - val_loss: 1.4428 - val_accuracy: 0.3653\n","Epoch 5/25\n","755/755 [==============================] - ETA: 0s - loss: 1.4776 - accuracy: 0.3478\n","Epoch 00005: val_loss did not improve from 1.44276\n","755/755 [==============================] - 135s 179ms/step - loss: 1.4776 - accuracy: 0.3478 - val_loss: 1.5309 - val_accuracy: 0.3952\n","Epoch 6/25\n","755/755 [==============================] - ETA: 0s - loss: 1.3900 - accuracy: 0.4038\n","Epoch 00006: val_loss improved from 1.44276 to 1.16421, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 100s 132ms/step - loss: 1.3900 - accuracy: 0.4038 - val_loss: 1.1642 - val_accuracy: 0.5265\n","Epoch 7/25\n","755/755 [==============================] - ETA: 0s - loss: 1.3009 - accuracy: 0.4575\n","Epoch 00007: val_loss improved from 1.16421 to 1.06683, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 71s 95ms/step - loss: 1.3009 - accuracy: 0.4575 - val_loss: 1.0668 - val_accuracy: 0.5733\n","Epoch 8/25\n","754/755 [============================>.] - ETA: 0s - loss: 1.2395 - accuracy: 0.4876\n","Epoch 00008: val_loss improved from 1.06683 to 1.02605, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 60s 80ms/step - loss: 1.2394 - accuracy: 0.4876 - val_loss: 1.0261 - val_accuracy: 0.5864\n","Epoch 9/25\n","755/755 [==============================] - ETA: 0s - loss: 1.1995 - accuracy: 0.5075\n","Epoch 00009: val_loss improved from 1.02605 to 0.94157, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 52s 69ms/step - loss: 1.1995 - accuracy: 0.5075 - val_loss: 0.9416 - val_accuracy: 0.6213\n","Epoch 10/25\n","755/755 [==============================] - ETA: 0s - loss: 1.1652 - accuracy: 0.5251\n","Epoch 00010: val_loss improved from 0.94157 to 0.92229, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 49s 65ms/step - loss: 1.1652 - accuracy: 0.5251 - val_loss: 0.9223 - val_accuracy: 0.6314\n","Epoch 11/25\n","754/755 [============================>.] - ETA: 0s - loss: 1.1493 - accuracy: 0.5325\n","Epoch 00011: val_loss improved from 0.92229 to 0.88546, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 46s 62ms/step - loss: 1.1493 - accuracy: 0.5325 - val_loss: 0.8855 - val_accuracy: 0.6505\n","Epoch 12/25\n","755/755 [==============================] - ETA: 0s - loss: 1.1264 - accuracy: 0.5471\n","Epoch 00012: val_loss improved from 0.88546 to 0.85816, saving model to /content/drive/My Drive/Colab Notebooks/Emotion_little_vgg.h5\n","755/755 [==============================] - 46s 61ms/step - loss: 1.1264 - accuracy: 0.5471 - val_loss: 0.8582 - val_accuracy: 0.6408\n","Epoch 13/25\n","754/755 [============================>.] - ETA: 0s - loss: 1.1054 - accuracy: 0.5573\n","Epoch 00013: val_loss did not improve from 0.85816\n","755/755 [==============================] - 43s 57ms/step - loss: 1.1055 - accuracy: 0.5573 - val_loss: 0.8627 - val_accuracy: 0.6532\n","Epoch 14/25\n","755/755 [==============================] - ETA: 0s - loss: 1.0892 - accuracy: 0.5613\n","Epoch 00014: val_loss did not improve from 0.85816\n","755/755 [==============================] - 45s 60ms/step - loss: 1.0892 - accuracy: 0.5613 - val_loss: 0.8612 - val_accuracy: 0.6583\n","Epoch 15/25\n","755/755 [==============================] - ETA: 0s - loss: 1.0733 - accuracy: 0.5745Restoring model weights from the end of the best epoch.\n","\n","Epoch 00015: val_loss did not improve from 0.85816\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","755/755 [==============================] - 44s 58ms/step - loss: 1.0733 - accuracy: 0.5745 - val_loss: 0.8672 - val_accuracy: 0.6539\n","Epoch 00015: early stopping\n"],"name":"stdout"}]}]}